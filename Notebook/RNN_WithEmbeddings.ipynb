{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import custom modules from current folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from simple_text_representation.classes import Text\n",
    "from simple_text_representation.models import Database\n",
    "import numpy as np\n",
    "# from nltk.draw.tree import draw_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = Database('educationalTexts', 'postgres', '', '0.0.0.0', 5432)\n",
    "path = r'http://localhost/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformToString(text):\n",
    "    textStr = ''\n",
    "\n",
    "    for paragraph in text:\n",
    "        for line in paragraph:\n",
    "            textStr = textStr + line\n",
    "    return textStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "textOfSeventhGrade = Text.getTexts(database, grade=7)\n",
    "textOfEightGrade = Text.getTexts(database, grade=8)\n",
    "textOfNineGrade = Text.getTexts(database, grade=9)\n",
    "textOfTenthGrade = Text.getTexts(database, grade=10)\n",
    "textOfEleventhGrade = Text.getTexts(database, grade=11)\n",
    "\n",
    "textsFormatedSG = [transformToString(textArr) for textArr in textOfSeventhGrade]\n",
    "textsFormatedEG = [transformToString(textArr) for textArr in textOfEightGrade]\n",
    "textsFormatedNG = [transformToString(textArr) for textArr in textOfNineGrade]\n",
    "textsFormatedTG = [transformToString(textArr) for textArr in textOfTenthGrade]\n",
    "textsFormatedEG = [transformToString(textArr) for textArr in textOfEleventhGrade]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((np.array(textsFormatedSG),\n",
    "                       np.array(textsFormatedEG),\n",
    "                       np.array(textsFormatedNG),\n",
    "                       np.array(textsFormatedTG),\n",
    "                       np.array(textsFormatedEG)  )) \n",
    "labels = np.concatenate((np.full(len(textsFormatedSG), 0),\n",
    "                         np.full(len(textsFormatedEG), 1),\n",
    "                         np.full(len(textsFormatedNG), 2),\n",
    "                         np.full(len(textsFormatedTG), 3),\n",
    "                         np.full(len(textsFormatedEG), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/herbert/.pyenv/versions/anaconda3-5.0.1/envs/jupyter3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLongestText(texts):\n",
    "    longest = -1\n",
    "\n",
    "    for text in texts:\n",
    "        longest = len(text) if (len(text) > longest) else longest\n",
    "    \n",
    "    return longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12715\n"
     ]
    }
   ],
   "source": [
    "# Try to build a the tokenizer for each sentence, instead for each words in a text.\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data)\n",
    "vocabSize = len(tokenizer.word_index) + 1\n",
    "encodedData = tokenizer.texts_to_sequences(data)\n",
    "maxLength = 500\n",
    "paddedData = pad_sequences(encodedData, maxlen=maxLength, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000654 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddingsIndex = dict()\n",
    "f = open('../SBW-vectors-300-min5.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddingsIndex[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddingsIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingMatrix = np.zeros((vocabSize, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embeddingVector = embeddingsIndex.get(word)\n",
    "    if embeddingVector is not None:\n",
    "        embeddingMatrix[i] = embeddingVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12715, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingMatrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    currentPrecision = precision(y_true, y_pred)\n",
    "    currentRecall = recall(y_true, y_pred)\n",
    "    return 2*((currentPrecision*currentRecall)/(currentPrecision+currentRecall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Embedding, LSTM\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embeddingLayer = Embedding(vocabSize, 300, weights=[embeddingMatrix], input_length=maxLength, trainable=False)\n",
    "model.add(embeddingLayer)\n",
    "model.add(LSTM(200))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 300)          3814500   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 200)               400800    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 4,216,305\n",
      "Trainable params: 401,805\n",
      "Non-trainable params: 3,814,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['acc', precision, recall, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140 samples, validate on 35 samples\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 4s 31ms/step - loss: 1.5844 - acc: 0.2071 - precision: 291714285.7143 - recall: 1.4455 - f1: 2.8911 - val_loss: 1.9525 - val_acc: 0.0000e+00 - val_precision: 1336857142.8571 - val_recall: 4.5143 - val_f1: 9.0286\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 4s 26ms/step - loss: 1.4735 - acc: 0.3929 - precision: 318571428.5714 - recall: 1.5392 - f1: 3.0784 - val_loss: 3.6246 - val_acc: 0.0000e+00 - val_precision: 1161428571.4286 - val_recall: 3.9143 - val_f1: 7.8286\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 3s 24ms/step - loss: 1.4263 - acc: 0.4357 - precision: 315714285.7143 - recall: 1.5738 - f1: 3.1476 - val_loss: 3.4966 - val_acc: 0.0000e+00 - val_precision: 1170571428.5714 - val_recall: 3.9429 - val_f1: 7.8857\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 4s 27ms/step - loss: 1.3651 - acc: 0.4929 - precision: 343428571.4286 - recall: 1.6903 - f1: 3.3806 - val_loss: 4.5970 - val_acc: 0.0000e+00 - val_precision: 1032571428.5714 - val_recall: 3.4857 - val_f1: 6.9714\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 4s 26ms/step - loss: 1.2703 - acc: 0.5000 - precision: 166857144.6978 - recall: 1.6508 - f1: 2.7326 - val_loss: 6.8987 - val_acc: 0.0000e+00 - val_precision: 1023428571.4286 - val_recall: 3.4571 - val_f1: 6.9143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1302b3da0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(paddedData, labels,\n",
    "  batch_size=32,\n",
    "  epochs=5,\n",
    "  verbose=1,\n",
    "  validation_split=0.2,\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features\n",
    "numberOfFeatures = 1024\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "features, target = make_classification(n_samples = 174,\n",
    "                                       n_features = numberOfFeatures,\n",
    "                                       n_informative = 3,\n",
    "                                       n_redundant = 0,\n",
    "                                       n_classes = 2,\n",
    "                                       weights = [.5, .5],\n",
    "                                       random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function returning a compiled network\n",
    "def createNetwork():\n",
    "    \n",
    "    model = Sequential()\n",
    "    embeddingLayer = Embedding(vocabSize, 300, weights=[embeddingMatrix], input_length=maxLength, trainable=False)\n",
    "    model.add(embeddingLayer)\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(200))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neuralNetwork = KerasClassifier(build_fn=createNetwork, \n",
    "                                 epochs=3, \n",
    "                                 batch_size=22, \n",
    "                                 verbose=1,\n",
    "                                 validation_split=0.2,\n",
    "                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92 samples, validate on 24 samples\n",
      "Epoch 1/3\n",
      "92/92 [==============================] - 8s 90ms/step - loss: 1.5604 - acc: 0.2500 - val_loss: 2.1125 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "92/92 [==============================] - 3s 37ms/step - loss: 1.3816 - acc: 0.3370 - val_loss: 3.8639 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "92/92 [==============================] - 3s 38ms/step - loss: 1.3963 - acc: 0.3913 - val_loss: 2.7925 - val_acc: 0.0000e+00\n",
      "59/59 [==============================] - 1s 9ms/step\n",
      "Train on 93 samples, validate on 24 samples\n",
      "Epoch 1/3\n",
      "93/93 [==============================] - 8s 89ms/step - loss: 1.5832 - acc: 0.5376 - val_loss: 1.6852 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "93/93 [==============================] - 3s 35ms/step - loss: 1.4528 - acc: 0.5806 - val_loss: 2.8798 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "93/93 [==============================] - 4s 38ms/step - loss: 1.3438 - acc: 0.5699 - val_loss: 3.1531 - val_acc: 0.0000e+00\n",
      "58/58 [==============================] - 1s 13ms/step\n",
      "Train on 93 samples, validate on 24 samples\n",
      "Epoch 1/3\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 1.5626 - acc: 0.5699 - val_loss: 1.6934 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "93/93 [==============================] - 3s 32ms/step - loss: 1.3838 - acc: 0.4409 - val_loss: 2.1726 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "93/93 [==============================] - 3s 33ms/step - loss: 1.0687 - acc: 0.5376 - val_loss: 2.9998 - val_acc: 0.0000e+00\n",
      "58/58 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate neural network using three-fold cross-validation\n",
    "cross_val_score(neuralNetwork, paddedData, labels, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8319"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtStr = transformToString(textOfTenthGrade[0])\n",
    "len(txtStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizerTest = Tokenizer()\n",
    "tokenizerTest.fit_on_texts([txtStr])\n",
    "vocabSizeTest = len(tokenizerTest.word_index) + 1\n",
    "encodedDataTest = tokenizerTest.texts_to_sequences(data)\n",
    "paddedDataTest = pad_sequences(encodedDataTest, maxlen=maxLength, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 500)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddedData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = model.predict(paddedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9302939 , 0.4392127 , 0.27340063, 0.22505705, 0.0183492 ],\n",
       "       [0.9302997 , 0.43920457, 0.27339292, 0.22504601, 0.0183496 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505705, 0.0183492 ],\n",
       "       [0.3600198 , 0.7308806 , 0.6234632 , 0.7994102 , 0.00160389],\n",
       "       [0.9302939 , 0.43921277, 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505705, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340066, 0.22505707, 0.01834919],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505705, 0.01834919],\n",
       "       [0.9302939 , 0.43921277, 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505705, 0.0183492 ],\n",
       "       [0.3923057 , 0.74577045, 0.62846714, 0.79817814, 0.00154904],\n",
       "       [0.93029547, 0.4392104 , 0.27339852, 0.22505398, 0.01834941],\n",
       "       [0.9302939 , 0.43921277, 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.43921277, 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340057, 0.22505698, 0.01834921],\n",
       "       [0.9303353 , 0.439159  , 0.27334702, 0.22498377, 0.01834759],\n",
       "       [0.9302939 , 0.4392127 , 0.27340066, 0.22505707, 0.01834919],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.43921277, 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340066, 0.22505707, 0.01834919],\n",
       "       [0.9303727 , 0.43911403, 0.27329963, 0.2249222 , 0.01834216],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505705, 0.0183492 ],\n",
       "       [0.9302939 , 0.43921268, 0.27340057, 0.22505698, 0.01834921],\n",
       "       [0.9302939 , 0.4392127 , 0.27340066, 0.22505705, 0.0183492 ],\n",
       "       [0.9302939 , 0.43921277, 0.27340063, 0.22505707, 0.01834919],\n",
       "       [0.9301789 , 0.44021702, 0.2738892 , 0.22669087, 0.01729378],\n",
       "       [0.9302939 , 0.4392127 , 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505705, 0.01834919],\n",
       "       [0.9302939 , 0.4392127 , 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.43921277, 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.9302969 , 0.4392084 , 0.27339658, 0.2250512 , 0.01834951],\n",
       "       [0.893611  , 0.4813383 , 0.3176517 , 0.30223787, 0.0101808 ],\n",
       "       [0.9302939 , 0.43921277, 0.27340063, 0.22505707, 0.01834919],\n",
       "       [0.38093522, 0.74248034, 0.6228573 , 0.7944057 , 0.00151386],\n",
       "       [0.930294  , 0.43921253, 0.2734004 , 0.22505674, 0.01834925],\n",
       "       [0.93069696, 0.43885517, 0.27292728, 0.22457822, 0.01814898],\n",
       "       [0.9187749 , 0.4557729 , 0.2894944 , 0.25284716, 0.01365338],\n",
       "       [0.9302939 , 0.4392127 , 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.92998624, 0.44056833, 0.27418628, 0.22723785, 0.01715739],\n",
       "       [0.9302939 , 0.43921277, 0.27340066, 0.22505707, 0.01834919],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.43921277, 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9302941 , 0.43921235, 0.27340028, 0.22505648, 0.01834925],\n",
       "       [0.9302939 , 0.43921277, 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.9303101 , 0.43919092, 0.27337947, 0.22502744, 0.01834949],\n",
       "       [0.28246754, 0.7721946 , 0.66149473, 0.8296448 , 0.00129616],\n",
       "       [0.2681328 , 0.7672583 , 0.66561663, 0.8371484 , 0.00132691],\n",
       "       [0.9302939 , 0.43921277, 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505705, 0.0183492 ],\n",
       "       [0.39417028, 0.7181981 , 0.6016582 , 0.7692133 , 0.00190703],\n",
       "       [0.9302948 , 0.43921134, 0.27339935, 0.22505514, 0.01834935],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.01834919],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.25505716, 0.78006005, 0.6635592 , 0.84540015, 0.00131076],\n",
       "       [0.93029565, 0.43921015, 0.2733982 , 0.22505355, 0.01834943],\n",
       "       [0.9302959 , 0.43920976, 0.2733979 , 0.22505306, 0.01834945],\n",
       "       [0.2781733 , 0.7779627 , 0.6604438 , 0.8113606 , 0.00137198],\n",
       "       [0.9302939 , 0.4392127 , 0.27340057, 0.22505698, 0.01834921],\n",
       "       [0.9302939 , 0.43921277, 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.26229486, 0.7777461 , 0.64785725, 0.8359452 , 0.00137055],\n",
       "       [0.29401714, 0.76337624, 0.6443858 , 0.81923217, 0.00147817],\n",
       "       [0.29223645, 0.77131546, 0.6358732 , 0.815562  , 0.00146619],\n",
       "       [0.31508636, 0.7506203 , 0.6347187 , 0.80637926, 0.00155333],\n",
       "       [0.691875  , 0.59971386, 0.45500043, 0.55534816, 0.00400871],\n",
       "       [0.2556956 , 0.7799914 , 0.6616148 , 0.8437007 , 0.00128241],\n",
       "       [0.25284985, 0.7809005 , 0.6618758 , 0.8417899 , 0.00132452],\n",
       "       [0.37905696, 0.73985434, 0.5896823 , 0.77840686, 0.00168482],\n",
       "       [0.26131046, 0.77182895, 0.68126047, 0.8386488 , 0.00132039],\n",
       "       [0.29165033, 0.7602607 , 0.635327  , 0.81749314, 0.00144211],\n",
       "       [0.28436032, 0.77310747, 0.63398516, 0.8215418 , 0.00134663],\n",
       "       [0.22982332, 0.7959567 , 0.658604  , 0.8567454 , 0.00126112],\n",
       "       [0.2914281 , 0.76609993, 0.65082   , 0.8283917 , 0.00138459],\n",
       "       [0.2789087 , 0.7681253 , 0.6326321 , 0.83127016, 0.0013556 ],\n",
       "       [0.9302939 , 0.43921277, 0.27340063, 0.22505702, 0.0183492 ],\n",
       "       [0.2698079 , 0.77219915, 0.68171364, 0.8313534 , 0.00128786],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.43921277, 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.2920686 , 0.7636244 , 0.66058135, 0.8178267 , 0.00136093],\n",
       "       [0.31959042, 0.7451397 , 0.6511165 , 0.805957  , 0.00153203],\n",
       "       [0.27570358, 0.76320463, 0.66579825, 0.8363449 , 0.00144536],\n",
       "       [0.24539167, 0.7729111 , 0.6867583 , 0.85472864, 0.00127408],\n",
       "       [0.30136076, 0.74745816, 0.6633556 , 0.821365  , 0.00139306],\n",
       "       [0.4187983 , 0.7067676 , 0.595797  , 0.75356495, 0.00204271],\n",
       "       [0.37391168, 0.71580476, 0.62854695, 0.7738711 , 0.00177247],\n",
       "       [0.48237824, 0.6767245 , 0.5720116 , 0.71139294, 0.0022791 ],\n",
       "       [0.29887244, 0.7519598 , 0.6523717 , 0.82155585, 0.00140639],\n",
       "       [0.2892302 , 0.7622195 , 0.66126007, 0.823394  , 0.00139182],\n",
       "       [0.24817115, 0.7703803 , 0.6828146 , 0.8482001 , 0.00132178],\n",
       "       [0.2832992 , 0.75870556, 0.6668509 , 0.82680506, 0.00140805],\n",
       "       [0.93068373, 0.43910494, 0.27302885, 0.22496456, 0.01787472],\n",
       "       [0.2601321 , 0.7657951 , 0.6852712 , 0.8416639 , 0.00132434],\n",
       "       [0.28645566, 0.75241077, 0.6682203 , 0.82359916, 0.00138862],\n",
       "       [0.25306317, 0.77798676, 0.6716381 , 0.85032064, 0.00129576],\n",
       "       [0.9302939 , 0.4392127 , 0.27340066, 0.22505705, 0.01834919],\n",
       "       [0.7465202 , 0.57215166, 0.4257008 , 0.5017536 , 0.00480242],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.28712004, 0.748683  , 0.67227185, 0.818916  , 0.00145595],\n",
       "       [0.26546684, 0.7724018 , 0.67785424, 0.83807117, 0.00127452],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505702, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9303209 , 0.43917698, 0.2733655 , 0.22500838, 0.01834893],\n",
       "       [0.9302939 , 0.43921277, 0.27340063, 0.22505705, 0.0183492 ],\n",
       "       [0.9302939 , 0.43921277, 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.3500001 , 0.7383712 , 0.6351577 , 0.7820826 , 0.00165995],\n",
       "       [0.27247196, 0.7703513 , 0.6468053 , 0.8407684 , 0.00136149],\n",
       "       [0.9302939 , 0.43921277, 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.34823662, 0.7257571 , 0.62900084, 0.79179686, 0.00176611],\n",
       "       [0.3847392 , 0.72269446, 0.6055367 , 0.781669  , 0.00180794],\n",
       "       [0.3487246 , 0.7367063 , 0.6067243 , 0.80612904, 0.00166453],\n",
       "       [0.3975638 , 0.7016992 , 0.56986725, 0.7825906 , 0.00185752],\n",
       "       [0.32060662, 0.7383191 , 0.6181309 , 0.8253848 , 0.00160607],\n",
       "       [0.29686025, 0.75270885, 0.63805676, 0.8324289 , 0.0014656 ],\n",
       "       [0.22505368, 0.786419  , 0.67486197, 0.8612543 , 0.00124141],\n",
       "       [0.4769781 , 0.68066067, 0.5670016 , 0.7177866 , 0.00231041],\n",
       "       [0.2838229 , 0.75556874, 0.6584185 , 0.83497   , 0.00138369],\n",
       "       [0.26826996, 0.7652577 , 0.6582176 , 0.8431348 , 0.00137403],\n",
       "       [0.28512254, 0.7610291 , 0.6441911 , 0.83015084, 0.00142418],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.01834919],\n",
       "       [0.9302939 , 0.43921277, 0.27340063, 0.22505705, 0.0183492 ],\n",
       "       [0.73979694, 0.5760356 , 0.4285435 , 0.509514  , 0.00470284],\n",
       "       [0.83970857, 0.52125144, 0.36356074, 0.38731527, 0.00713092],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505702, 0.01834919],\n",
       "       [0.9302939 , 0.4392127 , 0.27340057, 0.22505702, 0.01834921],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.01834919],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.35453102, 0.724529  , 0.62212896, 0.7947293 , 0.00176825],\n",
       "       [0.2676004 , 0.7600595 , 0.6617558 , 0.84740525, 0.00133789],\n",
       "       [0.26806414, 0.7481632 , 0.6549519 , 0.84527093, 0.00147451],\n",
       "       [0.28836125, 0.7588402 , 0.64434147, 0.84547096, 0.0013707 ],\n",
       "       [0.26483023, 0.7657056 , 0.6538957 , 0.85013247, 0.00129911],\n",
       "       [0.9304241 , 0.4390559 , 0.27323535, 0.22484252, 0.01833082],\n",
       "       [0.9298442 , 0.44084024, 0.27441698, 0.22767505, 0.01703595],\n",
       "       [0.2681009 , 0.7675708 , 0.6447954 , 0.8543419 , 0.00138191],\n",
       "       [0.9302939 , 0.43921277, 0.27340066, 0.22505707, 0.01834919],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.43921277, 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.9302941 , 0.43921235, 0.27340028, 0.22505648, 0.01834925],\n",
       "       [0.9302939 , 0.43921277, 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.9303101 , 0.43919092, 0.27337947, 0.22502744, 0.01834949],\n",
       "       [0.28246754, 0.7721946 , 0.66149473, 0.8296448 , 0.00129616],\n",
       "       [0.2681328 , 0.7672583 , 0.66561663, 0.8371484 , 0.00132691],\n",
       "       [0.9302939 , 0.43921277, 0.27340066, 0.22505707, 0.0183492 ],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505705, 0.0183492 ],\n",
       "       [0.39417028, 0.7181981 , 0.6016582 , 0.7692133 , 0.00190703],\n",
       "       [0.9302948 , 0.43921134, 0.27339935, 0.22505514, 0.01834935],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.01834919],\n",
       "       [0.9302939 , 0.4392127 , 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.25505716, 0.78006005, 0.6635592 , 0.84540015, 0.00131076],\n",
       "       [0.93029565, 0.43921015, 0.2733982 , 0.22505355, 0.01834943],\n",
       "       [0.9302959 , 0.43920976, 0.2733979 , 0.22505306, 0.01834945],\n",
       "       [0.2781733 , 0.7779627 , 0.6604438 , 0.8113606 , 0.00137198],\n",
       "       [0.9302939 , 0.4392127 , 0.27340057, 0.22505698, 0.01834921],\n",
       "       [0.9302939 , 0.43921277, 0.27340063, 0.22505707, 0.0183492 ],\n",
       "       [0.2622948 , 0.7777461 , 0.6478573 , 0.8359452 , 0.00137055],\n",
       "       [0.29401717, 0.76337624, 0.6443858 , 0.81923217, 0.00147817],\n",
       "       [0.29223642, 0.77131546, 0.6358732 , 0.815562  , 0.00146619],\n",
       "       [0.31508636, 0.7506203 , 0.6347188 , 0.80637926, 0.00155333],\n",
       "       [0.691875  , 0.59971386, 0.45500043, 0.55534816, 0.00400871],\n",
       "       [0.2556956 , 0.7799914 , 0.6616148 , 0.8437007 , 0.00128241],\n",
       "       [0.25284988, 0.7809004 , 0.6618757 , 0.8417899 , 0.00132452],\n",
       "       [0.37905693, 0.73985434, 0.5896823 , 0.77840686, 0.00168482],\n",
       "       [0.26131043, 0.77182883, 0.68126047, 0.8386488 , 0.00132039],\n",
       "       [0.29165033, 0.76026064, 0.635327  , 0.81749314, 0.00144211],\n",
       "       [0.28436032, 0.77310747, 0.63398516, 0.8215418 , 0.00134663],\n",
       "       [0.22982332, 0.7959567 , 0.658604  , 0.8567454 , 0.00126112],\n",
       "       [0.29142818, 0.7661    , 0.65082   , 0.8283917 , 0.00138459],\n",
       "       [0.27890867, 0.7681253 , 0.6326321 , 0.83127016, 0.0013556 ],\n",
       "       [0.9302938 , 0.4392127 , 0.27340063, 0.22505705, 0.01834921]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
